{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have 31000 baseline results.\n",
      "We have 526 experimental results.\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "import os\n",
    "import random\n",
    "import json\n",
    "from json import JSONEncoder\n",
    "\n",
    "def _default(self, obj):\n",
    "    return getattr(obj.__class__, \"to_json\", _default.default)(obj)\n",
    "\n",
    "_default.default = JSONEncoder().default\n",
    "JSONEncoder.default = _default\n",
    "\n",
    "from pathos import multiprocessing\n",
    "import logging\n",
    "import copy\n",
    "from pathlib import Path\n",
    "from typing import Tuple\n",
    "import re\n",
    "from z3.z3 import Solver, And, Or, Not, Bool, Int, sat\n",
    "\n",
    "baselines: Path = Path(\"/Users/austin/git/Sugarlyzer-results/recommended_space_ON/remove_errors_OFF/clang/axtls/baselines.json\")\n",
    "experimental_results: Path = Path(\"/Users/austin/git/Sugarlyzer-results/recommended_space_ON/remove_errors_OFF/clang/axtls/desugared.json\")\n",
    "\n",
    "with open(baselines) as f:\n",
    "    baselines = json.load(f)\n",
    "\n",
    "with open(experimental_results) as f:\n",
    "    experimental_results = json.load(f)\n",
    "\n",
    "lonely_baselines = copy.deepcopy(baselines)\n",
    "lonely_experimental_results = copy.deepcopy(experimental_results)\n",
    "\n",
    "class IntRange:\n",
    "    def __init__(self, lower_bound_inclusive, upper_bound_exclusive):\n",
    "        self.lower_bound_inclusive = lower_bound_inclusive\n",
    "        self.upper_bound_exclusive = upper_bound_exclusive\n",
    "\n",
    "    def __contains__(self, item):\n",
    "        return isinstance(item, int) and (self.lower_bound_inclusive <= item < self.upper_bound_exclusive)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"IntRange({self.lower_bound_inclusive, self.upper_bound_exclusive})\"\n",
    "\n",
    "    def __str__(self):\n",
    "        return f\"[{self.lower_bound_inclusive}:{self.upper_bound_exclusive})\"\n",
    "\n",
    "    def to_json(self):\n",
    "        return str(self)\n",
    "\n",
    "\n",
    "for e in experimental_results:\n",
    "    toks = e['original_line'].split(':')\n",
    "    try:\n",
    "        e['original_line'] = IntRange(int(toks[0]), int(toks[1]) + 1)\n",
    "    except Exception as ex:\n",
    "        e['original_line'] = []\n",
    "    #print('\\t'.join([\"experimental\", *[str(s) for s in e.values()]]).replace(\"\\n\", \"\"))\n",
    "\n",
    "    if e['function_line_range'] == 'ERROR':\n",
    "        e['function_line_range'] = []\n",
    "    else:\n",
    "        toks = e['function_line_range'].split(':')\n",
    "        try:\n",
    "            e['function_line_range'] = IntRange(int(toks[1]), int(toks[2]) + 1)\n",
    "        except Exception as ex:\n",
    "            logging.exception(f\"e was {e}\")\n",
    "    e['presence_condition'] = str(e['presence_condition'])\n",
    "\n",
    "print(f\"We have {len(baselines)} baseline results.\")\n",
    "print(f\"We have {len(experimental_results)} experimental results.\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 31000/31000 [01:10<00:00, 438.31it/s] \n"
     ]
    }
   ],
   "source": [
    "import tqdm\n",
    "\n",
    "\n",
    "def match_stats(baseline_result: dict, experimental_result: dict) -> Tuple:\n",
    "    \"\"\"\n",
    "    Returns a vector of different match information.\n",
    "    (a, b, c)\n",
    "    a = True iff baseline and experimental have the same line number, message, and file.\n",
    "    b = True iff baseline and experimental have the same message, file, and baseline is within experimental's function scope.\n",
    "    c = True iff baseline's configuration is compatible with experimental's presence condition.\n",
    "    \"\"\"\n",
    "\n",
    "    a = (baseline_result['message'] == experimental_result['sanitized_message'] and \\\n",
    "         baseline_result['input_line'] in experimental_result['original_line'] and\\\n",
    "         baseline_result['input_file'].split('.')[0] == experimental_result['input_file'].split('.')[0])\n",
    "\n",
    "    b = (baseline_result['message'] == experimental_result['sanitized_message'] and \\\n",
    "         baseline_result['input_line'] in experimental_result['function_line_range'] and\\\n",
    "         baseline_result['input_file'].split('.')[0] == experimental_result['input_file'].split('.')[0])\n",
    "\n",
    "    c = False\n",
    "\n",
    "    if experimental_result['presence_condition'] not in ['Or(None)', 'None'] and (a or b):  # Don't bother doing this expensive step when the file and line number are different.\n",
    "        baseline_var_mapping = {}\n",
    "        for var in baseline_result['configuration']:\n",
    "            if var.startswith('DEF'):\n",
    "                baseline_var_mapping[re.sub(r\"^DEF_(.*)\", \"\\1\", var)] = True\n",
    "            elif var.startswith('UNDEF'):\n",
    "                baseline_var_mapping[re.sub(r\"^UNDEF_(.*)\", \"\\1\", var)] = False\n",
    "            else:\n",
    "                raise RuntimeError(f\"Don't know how to handle variable {var}\")\n",
    "\n",
    "        s = Solver()\n",
    "        for var, val in baseline_var_mapping.items():\n",
    "            var = Bool(var)\n",
    "            if val:\n",
    "                s.add(var)\n",
    "            else:\n",
    "                s.add(Not(var))\n",
    "\n",
    "        for mat in re.findall(\"DEF_[a-zA-Z0-9_]+\", experimental_result['presence_condition']):\n",
    "            exec(f\"{mat} = Bool('{mat}')\")\n",
    "\n",
    "        for mat in re.findall(\"USE_[a-zA-Z0-9_]+\", experimental_result['presence_condition']):\n",
    "            exec(f\"{mat} = Int('{mat}')\")\n",
    "\n",
    "        while True:\n",
    "            try:\n",
    "                s.add(eval(experimental_result['presence_condition']))  # TODO Definitely need to do more transformation here.\n",
    "                break\n",
    "            except NameError as ne:\n",
    "                var = re.search(\"name '(.*)' is not defined\", str(ne))\n",
    "                exec(f\"{var.group(1)} = Int('{var.group(1)}')\")\n",
    "\n",
    "        c = s.check() == sat\n",
    "    return a, b, c\n",
    "\n",
    "def tupleize(func, args): return func(*args), tuple(args)\n",
    "\n",
    "summary = {}\n",
    "\n",
    "# Note that results depend on the order of keys in this dictionary, because once we find a match_stats for one level we do not keep searching for the next.\n",
    "#  E.g., for a given report, we will first look for results with which it has a (True, True, True) report. If it has one, we do not continue searching for\n",
    "#  matches for (False, True, True), (True, False, True), etc.\n",
    "result_hierarchy = {(True, True, True): 0, (False, True, True): 0, (True, False, True): 0, (True, True, False): 0, (False, True, False): 0, (False, False, True): 0, (True, False, False): 0, (False, False, False): 0}\n",
    "\n",
    "report = []\n",
    "for b in tqdm.tqdm(baselines):\n",
    "    # Results are (baseline, desugared, match tuple)\n",
    "    results = [(b, e, match_stats(b, e)) for e in experimental_results]\n",
    "    found = False\n",
    "    for r in result_hierarchy.keys():\n",
    "        for res in results:\n",
    "            if res[2] == r:\n",
    "                found = True\n",
    "                result_hierarchy[r] += 1\n",
    "                # -----\n",
    "                # Here is where you compile information about any specific reports you need. This block of code\n",
    "                # iterates through all baselines and finds the highest level of matching that is available.\n",
    "                # So, for example, if you wanted to collect all of the unmatched originals, you would uncomment out this line of code:\n",
    "                #\n",
    "                # if (r == (False, False, False)):\n",
    "                #     report.append(res[0])\n",
    "                break # DO NOT DELETE THE BREAK!\n",
    "        if found:\n",
    "            break\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Results"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import os\n",
    "print(\"Current working directory is \" + str(Path(os.curdir).absolute()))\n",
    "# Change this if you want the reports printed out differently. For example, if above you collected unmatched reports,\n",
    "#  then here, you probably want something like\n",
    "#\n",
    "# print(json.dumps(report, indent=2))\n",
    "#\n",
    "print(json.dumps(report, indent=2))\n",
    "print('-----------')\n",
    "print(f\"Number of baseline results: {len(baselines)}\")\n",
    "print(f\"Number of desugared results: {len(experimental_results)}\")\n",
    "print(f\"Number of exact matches: {result_hierarchy[(True, True, True)]}\")\n",
    "print(f\"Number of partial matches: {result_hierarchy[False, True, True]}\")\n",
    "print(f\"Number of unmatched: {sum(v for k, v in result_hierarchy.items() if k not in [(True, True, True), (False, True, True)])}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "|result_hierarchy = {(True, True, True): 0, (False, True, True): 0, (True, False, True): 0, (True, True, False): 0, (False, True, False): 0, (False, False, True): 0, (True, False, False): 0, (False, False, False): 0}\n",
    "\n",
    "for e in experimental_results:\n",
    "    results = [(b, e, match_stats(b, e)) for b in baselines]\n",
    "    found = False\n",
    "    for r in result_hierarchy.keys():\n",
    "        for res in results:\n",
    "            if res[2] == r:\n",
    "                found = True\n",
    "                result_hierarchy[r] += 1\n",
    "                break\n",
    "        if found:\n",
    "            break\n",
    "\n",
    "[print(f\"{k}: {v}\") for k, v in result_hierarchy.items()]\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point in the notebook, we have a few structures.\n",
    "- summary: A dictionary mapping 3-tuples corresponding to results to a list of pairs of results.\n",
    "- lonely_baselines: A list of baseline results for which no matching experimental result was found.\n",
    "- lonely_experimental_results: A list of experimental results for which no matching baseline was found."
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Sample\n",
    "\n",
    "This code randomly samples a result from each classification and prints it for inspection."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(json.dumps({\"summary\": {str(k): len(summary[k]) for k in summary.keys()}}))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import random\n",
    "for k, v in filter(lambda k: (k[0][0] or k[0][1]) and not k[0][2], summary.items()): # == str((False, False, False)), summary.items()):\n",
    "    print(str(k))\n",
    "    print(json.dumps(random.sample(v, k=max(1, len(v))), indent=2))\n",
    "    print(\"-----------------------------------------------\")\n",
    "#{k: v for k, v in summary.items() if k != str((False, False, False))}}, indent=4))\n",
    "print(f\"Lonely baselines: {len(lonely_baselines)}, Lonely exps: {len(lonely_experimental_results)}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "print(f\"Types of lonely baselines: \\n\" + json.dumps([s for s in sorted(lonely_baselines, key = lambda x: x['sanitized_message'])], indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(json.dumps([e for e in experimental_results if \"BUSYBOX/eef\" in e['input_file']], indent=2))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
